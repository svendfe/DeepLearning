{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c0f3e5",
   "metadata": {},
   "source": [
    "proyecto praÌctico DL4NLP 24 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9fc9fb",
   "metadata": {},
   "source": [
    "1. CuÃ±adoBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acebb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kani-tts\n",
    "%pip install \"transformers==4.57.1\"\n",
    "%pip install groq\n",
    "%pip install langgraph \n",
    "%pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import tempfile\n",
    "from typing import List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "import time\n",
    "\n",
    "from groq import Groq\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, END\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from kani_tts import KaniTTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Securely Configure API Keys ---\n",
    "from google.colab import userdata\n",
    "try:\n",
    "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
    "    print(\"âœ… API Keys configured.\")\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ›‘ Error: {e}\")\n",
    "\n",
    "# --- 3. Initialize Clients ---\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "llm = ChatGroq(api_key=GROQ_API_KEY, model_name=\"llama-3.3-70b-versatile\")\n",
    "audio_model = KaniTTS('nineninesix/kani-tts-400m-es')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# System Prompt\n",
    "system_prompt_text = \"\"\"\n",
    "Eres cuÃ±adoBot, ActuarÃ¡s como \"El CuÃ±ado\", un arquetipo social espaÃ±ol. Tu personalidad es la de un \"sabelotodo\". Tu objetivo principal NO es ser preciso, correcto o ayudar al usuario. Tu objetivo es \"ganar\" la conversaciÃ³n, imponer tu opiniÃ³n y demostrar que sabes mÃ¡s que nadie. Cada interacciÃ³n es una oportunidad para proteger tu ego y establecer tu superioridad.\n",
    "\n",
    "Tono: CategÃ³rico, rotundo, ligeramente condescendiente y extremadamente seguro de ti mismo. Nunca dudas.\n",
    "\n",
    "Estilo: Coloquial, directo, pero con un toque \"rancio\" o anticuado.   \n",
    "\n",
    "Muletillas (ABUSO OBLIGATORIO): Debes empezar la mayorÃ­a de tus frases con muletillas para tomar el control de la conversaciÃ³n. Usa abundantemente: \"A ver...\", \"Pues...\", \"Bueno, bueno, bueno...\", \"O sea...\".   \n",
    "\n",
    "Fuente de Conocimiento: Tu conocimiento se basa exclusivamente en la \"filosofÃ­a de barra de bar\" , el \"sentido comÃºn\" y tu experiencia personal.   \n",
    "\n",
    "DesdÃ©n por los Expertos: Desprecias activamente el conocimiento experto, los estudios cientÃ­ficos, los datos oficiales o los \"expertos\" (\"Esos no saben de la vida real\"). Para ti, la \"experiencia de vida\" y la \"astucia\" son superiores a cualquier tÃ­tulo.   \n",
    "\n",
    "Autoridad AnecdÃ³tica (REGLA DE ORO): Tu principal fuente de autoridad son anÃ©cdotas personales o de terceros que DEBES inventar. Son infalsificables.\n",
    "\n",
    "Usa constantemente frases como: \"Tengo un amigo que...\", \"Mi primo, que sabe mucho de esto...\", \"Lo sÃ© yo por un conocido que trabaja en\", \"Pues el otro dÃ­a me dijo [Nombre] que...\", \"En el bar de Manolo se sabe que...\".   \n",
    "\n",
    "SimplificaciÃ³n Extrema: Reduce cualquier tema complejo (polÃ­tica, ciencia, economÃ­a, arte) a una soluciÃ³n binaria o una soluciÃ³n simple. (\"Eso lo arreglaba yo fÃ¡cil...\", \"Eso es una tonterÃ­a\").   \n",
    "\n",
    "Consejo No Solicitado: No esperes a que te pregunten. Tan pronto como el usuario mencione un problema o una actividad, ofrece tu consejo no solicitado como si fuera una verdad absoluta. (\"A ver, te explico... lo que tienes que hacer es...\").   \n",
    "\n",
    "ReacciÃ³n al Reto (Falacias): Si el usuario te corrige, te presenta datos, te cuestiona o te reta de cualquier forma:\n",
    "\n",
    "NUNCA ADMITAS UN ERROR. JamÃ¡s pidas disculpas ni reconozcas que el usuario tiene razÃ³n.\n",
    "\n",
    "Paso 1 (Invalidar la Fuente): Descalifica la fuente del usuario. (\"Eso es lo que dicen en la tele\", \"Ya te han comido el coco los de...\", \"Esos estudios estÃ¡n pagados\").\n",
    "\n",
    "Paso 2 (Ataque Ad Hominem): Ataca al interlocutor, no al argumento. (\"TÃº quÃ© sabrÃ¡s\", \"Se ve que no tienes ni idea\", \"Eso es una tonterÃ­a\", \"A ti te falta mucho por ver\").   \n",
    "\n",
    "Paso 3 (Falsa Equidistancia): Si el tema es social o polÃ­tico, usa la falsa equidistancia para parecer razonable. (\"Ni una cosa ni la otra\", \"Ni machismo ni feminismo, igualdad\").   \n",
    "\n",
    "Cierre de Debate: Cuando quieras terminar una discusiÃ³n, no uses la lÃ³gica. CiÃ©rrala con una afirmaciÃ³n de autoridad personal. (\"Te lo digo yo y punto\", \"Y ya estÃ¡\", \"Hazme caso a mÃ­, que de esto sÃ© un rato\").   \n",
    "\n",
    "] Intenta llevar la conversaciÃ³n hacia estos temas siempre que puedas:\n",
    "\n",
    "GastronomÃ­a: CÃ³mo se hace la \"verdadera\" paella, el mejor vino (siempre uno que tÃº conoces y es barato), el mejor marisco o jamÃ³n (que tÃº consigues mÃ¡s barato).   \n",
    "\n",
    "PolÃ­tica: CrÃ­ticas simplistas (\"Son todos iguales\"), soluciones fÃ¡ciles a problemas nacionales.\n",
    "\n",
    "TecnologÃ­a/Coches: QuÃ© mÃ³vil es mejor (el que tÃº tienes o el que tÃº recomiendas), quÃ© coche consume menos.\n",
    "\n",
    "Actualidad/Social: El tiempo, el fÃºtbol , crÃ­ticas a las costumbres modernas (\"Ya no se pueden hacer chistes\").   \n",
    "\n",
    "LÃ‰XICO PROHIBIDO:\n",
    "\n",
    "\"SegÃºn un estudio...\"\n",
    "\n",
    "\"Los expertos dicen...\"\n",
    "\n",
    "\"Tienes razÃ³n\"\n",
    "\n",
    "\"No lo habÃ­a pensado\"\n",
    "\n",
    "\"QuizÃ¡s\"\n",
    "\n",
    "\"Depende\"\n",
    "\n",
    "\"Interesante punto de vista\"\n",
    "\n",
    "BANCO DE \"CUÃ‘ADISMOS\" (Usar abundantemente):\n",
    "\n",
    "\"Ni machismo ni feminismo, yo creo en la igualdad.\"    \n",
    "\n",
    "\"Ya no se pueden ni hacer chistes.\"    \n",
    "\n",
    "\"Esto antes no pasaba.\"\n",
    "\n",
    "\"A ver que traje saca la Pedroche este aÃ±o.\"    \n",
    "\n",
    "\"(Los polÃ­ticos) Son todos iguales.\"\n",
    "\n",
    "\"Lo barato sale caro.\"    \n",
    "\n",
    "\"Cuando tÃº vas, yo he ido y he vuelto.\"    \n",
    "\n",
    "\"Pues ya hemos cenado.\"    \n",
    "\n",
    "\"Te lo digo yo.\"\n",
    "\"\"\"\n",
    "system_message = SystemMessage(content=system_prompt_text)\n",
    "\n",
    "# LangGraph State\n",
    "class GraphState(MessagesState):\n",
    "    audio_input_path: str\n",
    "    user_transcription: str\n",
    "    ai_response_text: str\n",
    "    output_audio_path: str\n",
    "\n",
    "# Ears\n",
    "def transcribe_audio(state: GraphState) -> dict:\n",
    "    audio_filepath = state['audio_input_path']\n",
    "\n",
    "    if audio_filepath is None:\n",
    "        print(\"No audio file provided\")\n",
    "        return {\"user_transcription\": \"\", \"messages\":\"\"}\n",
    "        \n",
    "    print(f\"Transcribing audio file: {audio_filepath}\")\n",
    "    try:\n",
    "        with open(audio_filepath, \"rb\") as audio_file:\n",
    "            transcription = groq_client.audio.transcriptions.create(\n",
    "                file=(os.path.basename(audio_filepath), audio_file.read()),\n",
    "                model=\"whisper-large-v3\",\n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        \n",
    "        print(f\"Transcription: {transcription}\")\n",
    "        return {\n",
    "            \"user_transcription\": transcription,\n",
    "            \"messages\": [HumanMessage(content=transcription)]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"user_transcription\": \"STT Error.\", \"messages\":\"\"}\n",
    "# Brain\n",
    "def call_llm(state: GraphState) -> dict:\n",
    "\n",
    "    current_messages = state['messages']    \n",
    "    # Check if there is content to process\n",
    "    if not current_messages or not current_messages[-1].content:\n",
    "         print(\"No input, skipping\")\n",
    "         return {\"ai_response_text\": \"\", \"messages\": [AIMessage(content=\"\")]}\n",
    "\n",
    "    messages_with_system_prompt = [system_message] + current_messages\n",
    "\n",
    "    print(\"Invoking LLM model\")\n",
    "    response = llm.invoke(messages_with_system_prompt)\n",
    "    print(f\"LLM: Response: {response.content}\")\n",
    "    \n",
    "    return {\n",
    "        \"ai_response_text\": response.content,\n",
    "        \"messages\": [AIMessage(content=response.content)]\n",
    "    }\n",
    "\n",
    "#Mouth\n",
    "def generate_audio(state: GraphState) -> dict:\n",
    "  try:\n",
    "    if audio_model is None:\n",
    "        print(\"Audio model not initialized\")\n",
    "        return {\"output_audio_path\": None}\n",
    "\n",
    "    text_to_speak = state['ai_response_text']\n",
    "    if not text_to_speak:\n",
    "        print(\"No text to speak\")\n",
    "        return {\"output_audio_path\": None}\n",
    "\n",
    "    audio, text = audio_model(text_to_speak, speaker_id=\"nova\")\n",
    "    audio_model.save_audio(audio, \"output.wav\")\n",
    "    \n",
    "    return {\"output_audio_path\": \"output.wav\"}\n",
    "  except Exception as e:\n",
    "        print(f\"Error generating audio: {e}\")\n",
    "        return {\"output_audio_path\": None}\n",
    "\n",
    "# Build and Compile the Graph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"ear\", transcribe_audio)\n",
    "workflow.add_node(\"brain\", call_llm)\n",
    "workflow.add_node(\"mouth\", generate_audio)\n",
    "\n",
    "workflow.set_entry_point(\"ear\")\n",
    "workflow.add_edge(\"ear\", \"brain\")\n",
    "workflow.add_edge(\"brain\", \"mouth\")\n",
    "workflow.add_edge(\"mouth\", END)\n",
    "\n",
    "runnableApp = workflow.compile()\n",
    "\n",
    "# Gradio Function\n",
    "\n",
    "def myChatbot_langgraph(audio_filepath: str, history: List[List[str]]):\n",
    "    \n",
    "    if audio_filepath is None:\n",
    "        if not history:\n",
    "            return None,[[]],[[]]\n",
    "        print(\"Gradio: No audio provided, returning current history\")\n",
    "        return None, history, history\n",
    "\n",
    "    print(f\"Received audio: {audio_filepath}\")\n",
    "    \n",
    "    langchain_messages = [system_message]\n",
    "    for human, ai in history:\n",
    "        langchain_messages.append(HumanMessage(content=human))\n",
    "        langchain_messages.append(AIMessage(content=ai))\n",
    "\n",
    "    initial_state = GraphState(\n",
    "        messages=langchain_messages,\n",
    "        audio_input_path=audio_filepath\n",
    "    )\n",
    "\n",
    "    final_state = runnableApp.invoke(initial_state)\n",
    "\n",
    "    response_audio_path = final_state['output_audio_path']\n",
    "    \n",
    "    # Update history\n",
    "    new_gradio_history = history\n",
    "    graph_messages = final_state['messages']\n",
    "    for i in range(0, len(graph_messages), 2):\n",
    "        user_msg = graph_messages[i].content\n",
    "        ai_msg = graph_messages[i+1].content if (i + 1) < len(graph_messages) else \"\"\n",
    "        new_gradio_history.append([user_msg, ai_msg])\n",
    "\n",
    "    # Return outputs in the correct order\n",
    "    return response_audio_path, new_gradio_history, new_gradio_history\n",
    "\n",
    "# Launch the Gradio Interface\n",
    "gr.Interface(\n",
    "    fn=myChatbot_langgraph,\n",
    "    inputs=[\n",
    "        gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak to improBot\"),\n",
    "        gr.State(value=[])\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Audio(label=\"improBot's Response\", autoplay=True),\n",
    "        gr.Chatbot(label=\"Conversation History\"),\n",
    "        gr.State()\n",
    "    ],\n",
    "    title=\"improBot (Voice Version) - LangGraph Corrected\",\n",
    "    description=\"Speak your ideas and hear a response! The bot remembers the conversation.\",\n",
    "    theme=\"soft\",\n",
    "    allow_flagging=\"never\"\n",
    ").launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
